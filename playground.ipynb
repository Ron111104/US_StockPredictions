{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17aa9bfd-e44a-4754-9cd0-632a0e56b2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL raw Date range: 1980-12-12 to 2025-01-14\n",
      "AMD raw Date range: 1980-03-17 to 2025-01-14\n",
      "AMZN raw Date range: 1997-05-15 to 2025-01-14\n",
      "BA raw Date range: 1962-01-02 to 2025-01-14\n",
      "BX raw Date range: 2007-06-22 to 2025-01-14\n",
      "COST raw Date range: 1986-07-09 to 2025-01-14\n",
      "CRM raw Date range: 2004-06-23 to 2025-01-14\n",
      "DIS raw Date range: 1962-01-02 to 2025-01-14\n",
      "ENPH raw Date range: 2012-03-30 to 2025-01-14\n",
      "F raw Date range: 1972-06-01 to 2025-01-14\n",
      "GOOG raw Date range: 2004-08-19 to 2025-01-14\n",
      "INTC raw Date range: 1980-03-17 to 2025-01-14\n",
      "KO raw Date range: 1962-01-02 to 2025-01-14\n",
      "META raw Date range: 2012-05-18 to 2025-01-14\n",
      "MSFT raw Date range: 1986-03-13 to 2025-01-14\n",
      "NFLX raw Date range: 2002-05-23 to 2025-01-14\n",
      "NIO raw Date range: 2018-09-12 to 2025-01-14\n",
      "NOC raw Date range: 1981-12-31 to 2025-01-14\n",
      "PG raw Date range: 1962-01-02 to 2025-01-14\n",
      "PYPL raw Date range: 2015-07-06 to 2025-01-14\n",
      "TSLA raw Date range: 2010-06-29 to 2025-01-14\n",
      "TSM raw Date range: 1997-10-09 to 2025-01-14\n",
      "XPEV raw Date range: 2020-08-27 to 2025-01-14\n",
      "⚠️ XPEV has no data in 2021-09-30–2022-09-29\n",
      "ZS raw Date range: 2018-03-16 to 2025-01-14\n",
      "✅ Combined CSV saved at ./sentimentdataset2\\combined_data.csv (5796 rows)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ta   # pip install ta\n",
    "\n",
    "# === PARAMETERS ===\n",
    "raw_data_dir       = \"./sentimentdataset\"\n",
    "filtered_data_dir  = \"./sentimentdataset2\"\n",
    "combined_filename  = \"combined_data.csv\"\n",
    "\n",
    "# final date window for combined output\n",
    "final_start_date   = pd.to_datetime(\"2021-09-30\")\n",
    "final_end_date     = pd.to_datetime(\"2022-09-29\")\n",
    "\n",
    "# ensure output dir exists\n",
    "os.makedirs(filtered_data_dir, exist_ok=True)\n",
    "\n",
    "# TEMA helper\n",
    "def calculate_tema(series, window):\n",
    "    ema1 = ta.trend.EMAIndicator(close=series, window=window).ema_indicator()\n",
    "    ema2 = ta.trend.EMAIndicator(close=ema1,   window=window).ema_indicator()\n",
    "    ema3 = ta.trend.EMAIndicator(close=ema2,   window=window).ema_indicator()\n",
    "    return 3*ema1 - 3*ema2 + ema3\n",
    "\n",
    "# process one ticker file fully, then slice\n",
    "def process_csv(file_path, ticker):\n",
    "    # read & parse dates\n",
    "    df = pd.read_csv(file_path, parse_dates=[\"Date\"], dayfirst=False)\n",
    "    df.dropna(subset=[\"Date\"], inplace=True)\n",
    "    # normalize to naive datetime\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], utc=True).dt.tz_localize(None)\n",
    "\n",
    "    # DEBUG: show date range\n",
    "    print(f\"{ticker} raw Date range: {df['Date'].min().date()} to {df['Date'].max().date()}\")\n",
    "\n",
    "    # verify necessary columns\n",
    "    required = [\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        print(f\"⚠️ {ticker} missing columns {missing}; skipping.\")\n",
    "        return None\n",
    "\n",
    "    # keep base columns\n",
    "    df = df[[\"Date\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]].copy()\n",
    "\n",
    "    # calculate TA indicators on full range\n",
    "    for w in [14,26,50,100,200]:\n",
    "        df[f\"SMA_{w}\"]  = ta.trend.SMAIndicator(df.Close, window=w).sma_indicator()\n",
    "        df[f\"EMA_{w}\"]  = ta.trend.EMAIndicator(df.Close, window=w).ema_indicator()\n",
    "        df[f\"TEMA_{w}\"] = calculate_tema(df.Close, w)\n",
    "\n",
    "    bb = ta.volatility.BollingerBands(df.Close, window=20, window_dev=2)\n",
    "    df[\"BB_Hband\"]   = bb.bollinger_hband()\n",
    "    df[\"BB_Mband\"]   = bb.bollinger_mavg()\n",
    "    df[\"BB_Lband\"]   = bb.bollinger_lband()\n",
    "    df[\"RSI_14\"]     = ta.momentum.RSIIndicator(df.Close, window=14).rsi()\n",
    "    macd = ta.trend.MACD(df.Close, window_slow=26, window_fast=12, window_sign=9)\n",
    "    df[\"MACD\"]       = macd.macd()\n",
    "    df[\"MACD_Signal\"] = macd.macd_signal()\n",
    "    df[\"MACD_Hist\"]   = macd.macd_diff()\n",
    "\n",
    "    # derived & momentum features\n",
    "    df[\"Mean_HL\"]    = (df.High + df.Low) / 2.0\n",
    "    df[\"RMom_14\"]    = df.Close / df.Close.shift(14)\n",
    "    for w in [14,26,50,100,200]:\n",
    "        df[f\"MomTEMA_{w}_ofs1\"] = df[f\"TEMA_{w}\"] / df[f\"TEMA_{w}\"].shift(1)\n",
    "        df[f\"RCTEMA_{w}\"]       = df.Close / df[f\"TEMA_{w}\"]\n",
    "        df[f\"MomEMA_{w}_ofs1\"]  = df[f\"EMA_{w}\"] / df[f\"EMA_{w}\"].shift(1)\n",
    "\n",
    "    df[\"RTEMA_TEMA_14_50\"] = df.TEMA_14 / df.TEMA_50\n",
    "    df[\"REMA_EMA_14_50\"]   = df.EMA_14  / df.EMA_50\n",
    "    df[\"RSMA_SMA_14_50\"]   = df.SMA_14  / df.SMA_50\n",
    "    df[\"RVolSMA_20\"]       = df.Volume / df.Volume.rolling(20).mean()\n",
    "\n",
    "    # drop warm-up NaNs\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # slice final date window\n",
    "    # slice final date window (by date only)\n",
    "    df[\"DateOnly\"] = df[\"Date\"].dt.date\n",
    "    sliced = df[(df[\"DateOnly\"] >= final_start_date.date()) & \n",
    "                (df[\"DateOnly\"] <= final_end_date.date())].copy()\n",
    "    \n",
    "    if sliced.empty:\n",
    "        print(f\"⚠️ {ticker} has no data in {final_start_date.date()}–{final_end_date.date()}\")\n",
    "        return None\n",
    "    \n",
    "    # tag and format\n",
    "    sliced[\"Stock Name\"] = ticker\n",
    "    sliced[\"Date\"] = sliced[\"DateOnly\"].astype(str)\n",
    "    sliced.drop(columns=[\"DateOnly\"], inplace=True)\n",
    "    return sliced\n",
    "\n",
    "\n",
    "# main loop\n",
    "all_frames = []\n",
    "for fname in os.listdir(raw_data_dir):\n",
    "    if not fname.lower().endswith('.csv'):\n",
    "        continue\n",
    "    ticker = fname.replace('.csv','')\n",
    "    result = process_csv(os.path.join(raw_data_dir, fname), ticker)\n",
    "    if result is not None:\n",
    "        all_frames.append(result)\n",
    "\n",
    "# combine\n",
    "if all_frames:\n",
    "    combined = pd.concat(all_frames, ignore_index=True)\n",
    "    combined.sort_values(['Stock Name','Date'], inplace=True)\n",
    "    out_path = os.path.join(filtered_data_dir, combined_filename)\n",
    "    combined.to_csv(out_path, index=False)\n",
    "    print(f\"✅ Combined CSV saved at {out_path} ({len(combined)} rows)\")\n",
    "else:\n",
    "    print(\"⚠️ No data processed; check your files and date range.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1595cf-5754-46ab-9234-310eca38d509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
